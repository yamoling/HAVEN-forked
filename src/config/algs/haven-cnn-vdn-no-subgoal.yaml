# --- QMIX specific parameters ---

# use epsilon greedy action selector
action_selector:
  type: "epsilon_greedy"
  epsilon_start: 1.0
  epsilon_finish: 0.05
  epsilon_anneal_time: 50000

macro_action_selector:
  type: "epsilon_greedy"
  epsilon_start: 1.0
  epsilon_finish: 0.05
  epsilon_anneal_time: 50000

buffer_size: 5000
enable_haven_subgoals: false

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "haven_learner"
double_q: True
mixer: "vdn"
macro_mixer: "vdn"
value_mixer: "vdn"
name: "haven-cnn-vdn-no-subgoal"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

n_subgoals: 8
k: 3

macro_mac: "macro_mac"
macro_network: "macro-cnn"
macro_value_network: "value-cnn"
mean_weight: True
intrinsic_switch: 1
reward_switch: 1

agent: "cnn"